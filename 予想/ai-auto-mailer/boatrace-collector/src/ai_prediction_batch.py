"""
ç«¶è‰‡AIäºˆæƒ³ - äºˆæƒ³ç”Ÿæˆãƒãƒƒãƒ
ç· åˆ‡5åˆ†å‰ã«äºˆæƒ³ã‚’ç”Ÿæˆã—ã¦DBã«ä¿å­˜
"""
import os
import json
import pickle
from datetime import datetime, timezone, timedelta, date
from dotenv import load_dotenv
load_dotenv()

import psycopg2
from psycopg2.extras import RealDictCursor
import numpy as np

DATABASE_URL = os.environ.get('DATABASE_URL')
JST = timezone(timedelta(hours=9))

# ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
MODEL_DIR = os.path.join(os.path.dirname(__file__), 'models')
MODEL_PATH = os.path.join(MODEL_DIR, 'boatrace_ai_v1.0.pkl')
MODEL_VERSION = 'v1.0'

# ç«¶è‰‡å ´åãƒãƒƒãƒ—
STADIUM_NAMES = {
    '01': 'æ¡ç”Ÿ', '02': 'æˆ¸ç”°', '03': 'æ±Ÿæˆ¸å·', '04': 'å¹³å’Œå³¶',
    '05': 'å¤šæ‘©å·', '06': 'æµœåæ¹–', '07': 'è’²éƒ¡', '08': 'å¸¸æ»‘',
    '09': 'æ´¥', '10': 'ä¸‰å›½', '11': 'ã³ã‚ã“', '12': 'ä½ä¹‹æ±Ÿ',
    '13': 'å°¼å´', '14': 'é³´é–€', '15': 'ä¸¸äº€', '16': 'å…å³¶',
    '17': 'å®®å³¶', '18': 'å¾³å±±', '19': 'ä¸‹é–¢', '20': 'è‹¥æ¾',
    '21': 'èŠ¦å±‹', '22': 'ç¦å²¡', '23': 'å”æ´¥', '24': 'å¤§æ‘'
}


def load_model():
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {MODEL_PATH}")
        return None

    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)

    print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {MODEL_VERSION}")
    return model


def safe_float(val):
    """å®‰å…¨ã«æ•°å€¤å¤‰æ›"""
    if val is None:
        return 0.0
    try:
        return float(val)
    except (ValueError, TypeError):
        return 0.0


def get_race_features(cur, race_date, stadium_code, race_no):
    """ãƒ¬ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’å–å¾—"""
    cur.execute("""
        SELECT
            boat_no as boat_number,
            national_win_rate,
            local_win_rate,
            motor_2nd_rate as motor_2rate,
            boat_2nd_rate as boat_2rate,
            rank as grade
        FROM historical_programs
        WHERE race_date = %s AND stadium_code = %s AND race_no = %s
        ORDER BY boat_no
    """, (race_date, stadium_code, race_no))

    rows = cur.fetchall()

    if len(rows) != 6:
        return None, None

    # ç‰¹å¾´é‡ã‚’ä½œæˆ
    features = []
    boat_info = []

    for row in rows:
        features.extend([
            safe_float(row['national_win_rate']),
            safe_float(row['local_win_rate']),
            safe_float(row['motor_2rate']),
            safe_float(row['boat_2rate']),
        ])

        # ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’æ•°å€¤åŒ–
        grade_map = {'A1': 4, 'A2': 3, 'B1': 2, 'B2': 1}
        features.append(grade_map.get(row['grade'], 0))

        boat_info.append({
            'boat_no': row['boat_number'],
            'national_win_rate': safe_float(row['national_win_rate']),
            'local_win_rate': safe_float(row['local_win_rate']),
            'motor_2rate': safe_float(row['motor_2rate']),
            'grade': row['grade']
        })

    # å ´ã‚³ãƒ¼ãƒ‰ã€Rç•ªå·ã‚’è¿½åŠ 
    features.extend([int(stadium_code), int(race_no)])

    return np.array([features]), boat_info


def calculate_confidence(probs):
    """ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆæœ€å¤§ç¢ºç‡ã®è‰‡ã¨ãã®ä»–ã®å·®ï¼‰"""
    sorted_probs = sorted(probs, reverse=True)
    # 1ä½ã¨2ä½ã®å·® + 1ä½ã®ç¢ºç‡
    gap = sorted_probs[0] - sorted_probs[1]
    confidence = (sorted_probs[0] * 0.6 + gap * 0.4) * 100
    return min(100, max(0, confidence))


def generate_reasons(boat_info, probs):
    """äºˆæƒ³ç†ç”±ã‚’ç”Ÿæˆ"""
    reasons = []

    # å‹ç‡ãŒé«˜ã„è‰‡ã‚’ç‰¹å®š
    sorted_boats = sorted(enumerate(boat_info), key=lambda x: probs[x[0]], reverse=True)

    # ä¸Šä½3è‰‡ã®ç†ç”±
    for i, (idx, boat) in enumerate(sorted_boats[:3]):
        boat_no = idx + 1

        if i == 0:  # æœ¬å‘½
            if boat['grade'] == 'A1':
                reasons.append({
                    'type': 'positive',
                    'text': f"{boat_no}å·è‰‡: A1ãƒ©ãƒ³ã‚¯ã€å…¨å›½å‹ç‡{boat['national_win_rate']:.1f}%"
                })
            elif boat['national_win_rate'] >= 7.0:
                reasons.append({
                    'type': 'positive',
                    'text': f"{boat_no}å·è‰‡: å…¨å›½å‹ç‡{boat['national_win_rate']:.1f}%ï¼ˆé«˜å‹ç‡ï¼‰"
                })
            else:
                reasons.append({
                    'type': 'positive',
                    'text': f"{boat_no}å·è‰‡: æœ¬å‘½ï¼ˆAIäºˆæ¸¬å‹ç‡{probs[idx]*100:.1f}%ï¼‰"
                })

        elif i == 1:  # å¯¾æŠ—
            if boat['motor_2rate'] >= 40:
                reasons.append({
                    'type': 'positive',
                    'text': f"{boat_no}å·è‰‡: ãƒ¢ãƒ¼ã‚¿ãƒ¼2é€£ç‡{boat['motor_2rate']:.1f}%ï¼ˆå¥½èª¿æ©Ÿï¼‰"
                })
            elif boat['local_win_rate'] >= 6.0:
                reasons.append({
                    'type': 'positive',
                    'text': f"{boat_no}å·è‰‡: å½“åœ°å‹ç‡{boat['local_win_rate']:.1f}%ï¼ˆåœ°å…ƒâ—ï¼‰"
                })

        elif i == 2:  # ç©´
            if probs[idx] >= 0.10:
                reasons.append({
                    'type': 'warning',
                    'text': f"{boat_no}å·è‰‡: ç©´å€™è£œï¼ˆAIäºˆæ¸¬{probs[idx]*100:.1f}%ï¼‰"
                })

    return reasons[:3]  # æœ€å¤§3ã¤


def generate_predictions(model, cur, race_date, stadium_code, race_no):
    """1ãƒ¬ãƒ¼ã‚¹ã®äºˆæƒ³ã‚’ç”Ÿæˆ"""

    # ç‰¹å¾´é‡å–å¾—
    X, boat_info = get_race_features(cur, race_date, stadium_code, race_no)

    if X is None:
        return None

    # äºˆæ¸¬
    probs = model.predict(X)[0]  # 6è‰‡ã®å‹ç‡

    # ä¿¡é ¼åº¦è¨ˆç®—
    confidence = calculate_confidence(probs)

    # å„åˆ¸ç¨®ã®äºˆæ¸¬
    sorted_indices = np.argsort(probs)[::-1]  # å‹ç‡é«˜ã„é †

    # å˜å‹
    tansho = int(sorted_indices[0] + 1)

    # 2é€£å˜ãƒ»2é€£è¤‡
    top2 = sorted(sorted_indices[:2] + 1)
    nirentan = f"{sorted_indices[0]+1}-{sorted_indices[1]+1}"
    nirenfuku = f"{top2[0]}-{top2[1]}"

    # 3é€£å˜ãƒ»3é€£è¤‡
    top3 = sorted(sorted_indices[:3] + 1)
    sanrentan = f"{sorted_indices[0]+1}-{sorted_indices[1]+1}-{sorted_indices[2]+1}"
    sanrenfuku = f"{top3[0]}-{top3[1]}-{top3[2]}"

    # ç†ç”±ç”Ÿæˆ
    reasons = generate_reasons(boat_info, probs)

    # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    feature_importance = []
    for i, boat in enumerate(boat_info):
        if probs[i] == max(probs):
            feature_importance.append({
                'feature': f'{i+1}å·è‰‡å…¨å›½å‹ç‡',
                'impact': probs[i]
            })

    # äºˆæƒ³ãƒ‡ãƒ¼ã‚¿
    predictions_json = {
        'tansho': {'boat': tansho, 'probability': float(probs[sorted_indices[0]])},
        'fukusho': [
            {'boat': int(sorted_indices[0]+1), 'probability': float(probs[sorted_indices[0]])},
            {'boat': int(sorted_indices[1]+1), 'probability': float(probs[sorted_indices[1]])}
        ],
        'nirentan': [
            {'combination': nirentan, 'probability': float(probs[sorted_indices[0]] * probs[sorted_indices[1]])}
        ],
        'nirenfuku': [
            {'combination': nirenfuku, 'probability': float(probs[sorted_indices[0]] * probs[sorted_indices[1]] * 1.2)}
        ],
        'sanrentan': [
            {'combination': sanrentan, 'probability': float(probs[sorted_indices[0]] * probs[sorted_indices[1]] * probs[sorted_indices[2]])}
        ],
        'sanrenfuku': [
            {'combination': sanrenfuku, 'probability': float(probs[sorted_indices[0]] * probs[sorted_indices[1]] * probs[sorted_indices[2]] * 1.5)}
        ]
    }

    return {
        'confidence': confidence,
        'tansho_prediction': tansho,
        'nirentan_prediction': nirentan,
        'nirenfuku_prediction': nirenfuku,
        'sanrentan_prediction': sanrentan,
        'sanrenfuku_prediction': sanrenfuku,
        'predictions_json': predictions_json,
        'reasons_json': reasons,
        'feature_importance_json': feature_importance
    }


def save_prediction(cur, race_date, stadium_code, race_no, prediction):
    """äºˆæƒ³ã‚’DBã«ä¿å­˜"""
    cur.execute("""
        INSERT INTO ai_predictions (
            race_date, stadium_code, race_number,
            confidence, tansho_prediction,
            nirentan_prediction, nirenfuku_prediction,
            sanrentan_prediction, sanrenfuku_prediction,
            predictions_json, reasons_json, feature_importance_json,
            model_version, predicted_at
        ) VALUES (
            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
        )
        ON CONFLICT (race_date, stadium_code, race_number)
        DO UPDATE SET
            confidence = EXCLUDED.confidence,
            tansho_prediction = EXCLUDED.tansho_prediction,
            nirentan_prediction = EXCLUDED.nirentan_prediction,
            nirenfuku_prediction = EXCLUDED.nirenfuku_prediction,
            sanrentan_prediction = EXCLUDED.sanrentan_prediction,
            sanrenfuku_prediction = EXCLUDED.sanrenfuku_prediction,
            predictions_json = EXCLUDED.predictions_json,
            reasons_json = EXCLUDED.reasons_json,
            feature_importance_json = EXCLUDED.feature_importance_json,
            model_version = EXCLUDED.model_version,
            predicted_at = EXCLUDED.predicted_at
    """, (
        race_date, stadium_code, race_no,
        prediction['confidence'],
        prediction['tansho_prediction'],
        prediction['nirentan_prediction'],
        prediction['nirenfuku_prediction'],
        prediction['sanrentan_prediction'],
        prediction['sanrenfuku_prediction'],
        json.dumps(prediction['predictions_json']),
        json.dumps(prediction['reasons_json']),
        json.dumps(prediction['feature_importance_json']),
        MODEL_VERSION,
        datetime.now(JST)
    ))


def predict_single_race(database_url: str, race_date: str, stadium_code: str, race_no: int) -> dict:
    """
    ç›´å‰äºˆæƒ³: 1ãƒ¬ãƒ¼ã‚¹åˆ†ã®AIäºˆæƒ³ã‚’ç”Ÿæˆã—ã¦DBã«ä¿å­˜

    Args:
        database_url: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URL
        race_date: ãƒ¬ãƒ¼ã‚¹æ—¥ï¼ˆYYYYMMDDå½¢å¼ï¼‰
        stadium_code: å ´ã‚³ãƒ¼ãƒ‰ï¼ˆ01~24ï¼‰
        race_no: ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼ˆ1~12ï¼‰

    Returns:
        dict: äºˆæƒ³çµæœï¼ˆæˆåŠŸæ™‚ï¼‰ã€Noneï¼ˆå¤±æ•—æ™‚ï¼‰
    """
    import logging
    logger = logging.getLogger(__name__)

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model = load_model()
    if model is None:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
        return None

    conn = None
    try:
        conn = psycopg2.connect(database_url, cursor_factory=RealDictCursor)
        cur = conn.cursor()

        # äºˆæƒ³ç”Ÿæˆ
        prediction = generate_predictions(model, cur, race_date, stadium_code, race_no)

        if prediction is None:
            logger.warning(f"äºˆæƒ³ç”Ÿæˆå¤±æ•—: {stadium_code} {race_no}R - ç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼")
            return None

        # DBä¿å­˜
        # race_dateãŒYYYYMMDDæ–‡å­—åˆ—ã®å ´åˆã€dateå‹ã«å¤‰æ›
        if isinstance(race_date, str) and len(race_date) == 8:
            race_date_obj = datetime.strptime(race_date, '%Y%m%d').date()
        else:
            race_date_obj = race_date

        save_prediction(cur, race_date_obj, stadium_code, race_no, prediction)
        conn.commit()

        stadium_name = STADIUM_NAMES.get(stadium_code, stadium_code)
        logger.info(f"âœ… AIäºˆæƒ³ç”Ÿæˆ: {stadium_name} {race_no}R - ä¿¡é ¼åº¦: {prediction['confidence']:.1f}%")

        return {
            'stadium_code': stadium_code,
            'stadium_name': stadium_name,
            'race_number': race_no,
            'confidence': prediction['confidence'],
            'tansho': prediction['tansho_prediction'],
            'nirentan': prediction['nirentan_prediction'],
            'nirenfuku': prediction['nirenfuku_prediction'],
            'sanrentan': prediction['sanrentan_prediction'],
        }

    except Exception as e:
        logger.error(f"AIäºˆæƒ³ã‚¨ãƒ©ãƒ¼: {stadium_code} {race_no}R - {e}")
        if conn:
            conn.rollback()
        return None

    finally:
        if conn:
            conn.close()


def run_batch(target_date=None):
    """ãƒãƒƒãƒå®Ÿè¡Œ"""
    print("=" * 60)
    print("ç«¶è‰‡AIäºˆæƒ³ - äºˆæƒ³ç”Ÿæˆãƒãƒƒãƒ")
    print("=" * 60)

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model = load_model()
    if model is None:
        return

    # DBæ¥ç¶š
    conn = psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)
    cur = conn.cursor()

    # å¯¾è±¡æ—¥ï¼ˆYYYYMMDDå½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›ï¼‰
    if target_date is None:
        target_date = datetime.now(JST).date()

    race_date_str = target_date.strftime('%Y%m%d')
    print(f"\nğŸ“… å¯¾è±¡æ—¥: {target_date} ({race_date_str})")

    # ä»Šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—
    cur.execute("""
        SELECT DISTINCT stadium_code, race_no as race_number
        FROM historical_programs
        WHERE race_date = %s
        ORDER BY stadium_code, race_no
    """, (race_date_str,))

    races = cur.fetchall()
    print(f"   å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: {len(races)}ä»¶")

    # å„ãƒ¬ãƒ¼ã‚¹ã§äºˆæƒ³ç”Ÿæˆ
    success_count = 0
    for race in races:
        stadium_code = race['stadium_code']
        race_no = race['race_number']

        prediction = generate_predictions(model, cur, race_date_str, stadium_code, race_no)

        if prediction:
            save_prediction(cur, target_date, stadium_code, race_no, prediction)
            success_count += 1
            success_count += 1
            stadium_name = STADIUM_NAMES.get(stadium_code, stadium_code)
            print(f"   âœ… {stadium_name} {race_no}R - ä¿¡é ¼åº¦: {prediction['confidence']:.1f}%")

    conn.commit()
    conn.close()

    print(f"\n" + "=" * 60)
    print(f"âœ… äºˆæƒ³ç”Ÿæˆå®Œäº†: {success_count}/{len(races)}ä»¶")
    print("=" * 60)


if __name__ == "__main__":
    run_batch()
