# 技術仕様書：競艇データ自動収集システム

## 1. はじめに

本仕様書は、競艇公式サイトからレースに関連するあらゆる情報を自動収集し、分析可能な形式でデータベースに蓄積するためのシステム（以下、本システム）の技術仕様を定義するものです。

ご要望に基づき、Renderの有料サービス（PostgreSQL, Cron Job）を活用し、秒単位でのオッズ変動を含む網羅的なデータ収集を実現します。

## 2. システムアーキテクチャ

本システムは、以下のコンポーネントで構成されます。

- **データ収集バッチ (Python)**: 競艇公式サイトをスクレイピングし、レース情報やオッズデータを取得するコアモジュール。Render Cron Jobとして定期実行されます。
- **データベース (PostgreSQL)**: 収集したデータを格納する永続ストレージ。Renderでホストされている `kokotomo-db-staging` を利用します。
- **スケジューラ (Render Cron Job)**: データ収集バッチを定義されたスケジュール（例: 5分ごと、30分ごと）で実行します。

![システム構成図](https://i.imgur.com/example.png)  <!-- 後で実際の図に置き換える -->

## 3. データ収集戦略

### 3.1. 収集対象データ

| データ種別 | 内容 | 収集方法 |
| :--- | :--- | :--- |
| **レース情報** | 開催日、競艇場、レース番号、タイトル、距離など | `pyjpboatrace` または直接スクレイピング |
| **出走表** | 艇番、選手情報、モーター番号、ボート番号など | `pyjpboatrace` |
| **時系列オッズ** | 単勝、複勝、2連単/複、3連単/複、拡連複の全オッズ | `pyjpboatrace` または直接スクレイピング |
| **直前情報** | 天候、風向、風速、波高、展示タイム、選手体重など | `pyjpboatrace` |
| **レース結果** | 着順、払戻金、人気順など | `pyjpboatrace` |

### 3.2. 収集アプローチ

- **基本方針**: 公式サイトへの負荷を最小限に抑えつつ、データの網羅性とリアルタイム性を両立させるため、Pythonライブラリ `pyjpboatrace` を主軸に利用します。このライブラリは公式サイトの構造変更に追従しており、安定したデータ取得が期待できます。
- **リアルタイム収集**: 開催中のレースに対し、複数のCron Jobを組み合わせることで、収集頻度を動的に変更します。
  - **通常収集 (30分ごと)**: 全開催場のレース情報を巡回し、オッズを収集。
  - **高頻度収集 (5分ごと)**: 締切が近いレースに絞り、オッズの変動をより詳細に追跡。
- **過去データ収集**: 毎日深夜にバッチ処理を実行し、過去のレース結果やオッズデータを収集・蓄積します。

## 4. データベース設計

RenderのPostgreSQL (`kokotomo-db-staging`) 上に、以下のテーブルを構築します。詳細は添付の `db_schema.sql` を参照してください。

### 主要テーブル一覧

| テーブル名 | 概要 | 主なカラム |
| :--- | :--- | :--- |
| `stadiums` | 競艇場マスター | `stadium_code`, `name` |
| `racers` | レーサーマスター | `racer_id`, `name`, `rank` |
| `races` | レース基本情報 | `id`, `race_date`, `stadium_code`, `race_number` |
| `race_entries` | 出走表 | `race_id`, `boat_number`, `racer_id` |
| `odds` | **時系列オッズデータ** | `race_id`, `odds_type`, `bet_combination`, `odds_value`, `scraped_at` |
| `before_race_info` | 直前情報 | `race_id`, `weather`, `wind_speed`, `temperature` |
| `race_results` | レース結果 | `race_id`, `weather` |
| `payouts` | 払戻金データ | `race_result_id`, `odds_type`, `payout_amount` |
| `collection_logs` | 収集処理のログ | `collection_type`, `status`, `error_message` |

### 時系列オッズの実現

本システムの核となる `odds` テーブルは、**`scraped_at` カラムに収集時刻を秒単位で記録**します。これにより、同一レース・同一組み合わせのオッズであっても、異なる時刻のデータは別レコードとして保存され、オッズの時系列的な変動分析が可能になります。

```sql
-- 例: 特定レースの三連単「1-2-3」のオッズ推移を取得
SELECT odds_value, scraped_at
FROM odds
WHERE race_id = (SELECT id FROM races WHERE race_date = '2026-01-04' AND stadium_code = 1 AND race_number = 1)
  AND odds_type = 'trifecta'
  AND bet_combination = '1-2-3'
ORDER BY scraped_at ASC;
```

## 5. 実装コード

実装コード一式は `boatrace-collector.zip` に同梱します。主要なファイルは以下の通りです。

- `src/collector_advanced.py`: `pyjpboatrace` を利用したデータ収集のメインロジック。
- `src/cron_job.py`: Render Cron Jobから呼び出されるエントリポイント。
- `src/init_db.py`: データベースのテーブルを初期化するスクリプト。
- `render.yaml`: Renderへのデプロイ定義ファイル（Blueprint）。
- `requirements.txt`: Pythonの依存パッケージリスト。
- `README.md`: セットアップと運用のための詳細な手順書。

## 6. デプロイと運用

### 6.1. デプロイ手順

1.  **GitHubリポジトリ作成**: 同梱のソースコードをGitHubのプライベートリポジトリにプッシュします。
2.  **Render Blueprintデプロイ**: Renderダッシュボードから「New」→「Blueprint」を選択し、作成したリポジトリを接続します。`render.yaml` が自動的に読み込まれ、以下のCron Jobが設定されます。
    - `boatrace-odds-collector` (通常収集)
    - `boatrace-odds-highfreq` (高頻度収集)
    - `boatrace-historical-collector` (過去データ収集)
3.  **データベース接続**: 各Cron Jobの環境変数 `DATABASE_URL` が、既存の `kokotomo-db-staging` を参照するように設定します。
4.  **データベース初期化**: RenderのShell機能を使って、`python src/init_db.py` を一度だけ実行し、データベースにテーブルを作成します。

### 6.2. 運用

- デプロイ後は、RenderのCron Jobが自動的にデータ収集を実行します。
- 収集状況はRenderのログ画面、またはデータベースの `collection_logs` テーブルで確認できます。
- 公式サイトの仕様変更があった場合は、`collector_advanced.py` を中心にメンテナンスが必要になる可能性があります。

## 7. 今後の拡張性

- **データ分析API**: 収集したデータを外部から利用するためのAPIをFastAPIなどで構築。
- **機械学習モデル**: 蓄積したデータを基に、レース結果を予測する機械学習モデルを開発。
- **ダッシュボード**: 収集状況や分析結果を可視化するWebダッシュボードを構築。

以上


### `racer_period_stats` テーブル

レーサーの期別成績データを格納します。ファン手帳データソースからインポートされます。

| カラム名 | データ型 | 説明 |
| :--- | :--- | :--- |
| `id` | integer | 主キー |
| `racer_no` | character varying | 選手登録番号（例: 4892） |
| `data_year` | integer | データ年（例: 2024） |
| `data_period` | integer | 期（1=前期: 5月-10月, 2=後期: 11月-4月） |
| `name_kanji` | character varying | 選手名（漢字） |
| `name_kana` | character varying | 選手名（カナ） |
| `branch` | character varying | 支部（例: 福岡） |
| `rank` | character varying | 級別（A1, A2, B1, B2） |
| `win_rate` | numeric | 勝率 |
| `place_rate` | numeric | 2連対率 |
| `first_count` | integer | 1着回数 |
| `second_count` | integer | 2着回数 |
| `race_count` | integer | 出走回数 |
| `avg_start_timing` | numeric | 平均ST |
| `prev_ability_index` | numeric | 前期能力指数 |
| `current_ability_index` | numeric | 当期能力指数 |
| `created_at` | timestamp | 作成日時 |

### `batch_import_progress` テーブル

バッチ処理によるデータインポートの進捗状況を管理します。

| カラム名 | データ型 | 説明 |
| :--- | :--- | :--- |
| `id` | SERIAL PRIMARY KEY | 主キー |
| `data_type` | VARCHAR(50) | データ種別（'racer', 'race', 'program'） |
| `target_key` | VARCHAR(50) | 処理対象のキー（例: '2023_1'） |
| `status` | VARCHAR(20) | 状態（pending, success, failed, skipped） |
| `file_path` | VARCHAR(255) | ダウンロードしたファイルパス |
| `imported_count` | INTEGER | インポートしたレコード数 |
| `message` | TEXT | メッセージやエラー詳細 |
| `started_at` | TIMESTAMP | 処理開始日時 |
| `completed_at` | TIMESTAMP | 処理完了日時 |
